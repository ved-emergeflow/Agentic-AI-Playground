{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T11:01:51.510149Z",
     "start_time": "2025-11-07T11:01:48.343232Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, Literal, List, Any\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import after_model\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.types import Command, interrupt\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langgraph.runtime import Runtime\n",
    "from langgraph.graph import add_messages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.stores import InMemoryStore\n",
    "# from langchain_ollama import ChatOllama\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aa2d605119b3fcb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T11:11:19.879301Z",
     "start_time": "2025-11-07T11:11:19.868905Z"
    }
   },
   "outputs": [],
   "source": [
    "class RLAgentState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    user_input: str\n",
    "    steps: str\n",
    "    reasoning: str\n",
    "    changes: list[str]\n",
    "    first_response: str\n",
    "    current_response: str\n",
    "    final_response: str\n",
    "    jump_to: str\n",
    "    content: list[Any]\n",
    "    insights: str\n",
    "    first_run: bool\n",
    "    counter: int\n",
    "    max_loop: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7e841b475dbb4a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T11:01:51.530088Z",
     "start_time": "2025-11-07T11:01:51.525200Z"
    }
   },
   "outputs": [],
   "source": [
    "store = InMemoryStore()\n",
    "user_id = '1'\n",
    "namespace = (user_id, 'insights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dac98f66ec22bf2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T11:01:51.560101Z",
     "start_time": "2025-11-07T11:01:51.536459Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(\n",
    "    model='gemini-2.5-flash',\n",
    "    temperature=0.2,\n",
    "    api_key=os.getenv('GOOGLE_API_KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c5d4b130b4073a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T11:01:51.570706Z",
     "start_time": "2025-11-07T11:01:51.566416Z"
    }
   },
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchRun()\n",
    "# search.invoke(\"Obama's first name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "723b8fa1305f79e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T11:01:51.579525Z",
     "start_time": "2025-11-07T11:01:51.576743Z"
    }
   },
   "outputs": [],
   "source": [
    "tools = [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c178d92b37e35387",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T11:01:51.595745Z",
     "start_time": "2025-11-07T11:01:51.584824Z"
    }
   },
   "outputs": [],
   "source": [
    "search_agent = create_agent(model=model, tools=tools, state_schema=RLAgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7319581b139795dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T11:01:51.607263Z",
     "start_time": "2025-11-07T11:01:51.601669Z"
    }
   },
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2dfd264e7f417ab3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T11:01:51.620136Z",
     "start_time": "2025-11-07T11:01:51.614148Z"
    }
   },
   "outputs": [],
   "source": [
    "class Reasoning(BaseModel):\n",
    "    steps: str = Field(description='All the planned steps in order', min_length=1)\n",
    "    reasoning: str = Field(description='Reasoning and thought process', min_length=1)\n",
    "\n",
    "class Research(BaseModel):\n",
    "    target_age_group: Literal['18 and below','18-45','45 and above']\n",
    "    target_gender: Literal['Male','Female', 'Non-Binary']\n",
    "    target_demographic: str = Field(description='Category based on interests', min_length=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4791b338e96c9e49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T11:01:51.633274Z",
     "start_time": "2025-11-07T11:01:51.625359Z"
    }
   },
   "outputs": [],
   "source": [
    "reasoning_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are given a user input {input}. Your job is to plan your steps and mention your reasoning/ thought process behind your planning. You have these tools: {tools},\n",
    "    In your reasoning mention your indepth thought process and explanations as to why you think this is the correct approach.\n",
    "    \"\"\"\n",
    ")\n",
    "reasoning_chain = reasoning_prompt | model.with_structured_output(Reasoning)\n",
    "\n",
    "reasoning_with_insights_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are given a user input {input} and insights from previous runs {insights}. Your job is to plan your steps for tackling the query and mention your reasoning or thought process behind your planning for each step. You have these tools: {tools}.\n",
    "    In your reasoning mention your indepth thought process and explanations as to why you think this is the correct approach.\n",
    "    \"\"\"\n",
    ")\n",
    "reasoning_with_insights_chain = reasoning_with_insights_prompt | model.with_structured_output(Reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903a0d87ecc3a909",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T11:01:51.648222Z",
     "start_time": "2025-11-07T11:01:51.641085Z"
    }
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_browser(query : str | None, runtime: ToolRuntime[None | RLAgentState]) -> Command:\n",
    "    \"\"\"\n",
    "    This tool calls another agent who search the web to fnd results\n",
    "    :param query: str\n",
    "    :return: Command\n",
    "    \"\"\"\n",
    "    messages = runtime.state['messages']\n",
    "    # tool_call_id = state['messages'][-1].tool_calls[-1]['id']\n",
    "\n",
    "    res = search_agent.invoke([SystemMessage(content='You are an agent who can use search tools to fnd the most relevant texts based on the user queries from the web')] + messages)\n",
    "\n",
    "    # res = search_agent.invoke({\n",
    "    #     'messages': SystemMessage(content='You are an agent who can use search tools to fnd the most relevant texts based on the user queries from the web') + HumanMessage(content=query),\n",
    "    # })\n",
    "\n",
    "    return Command(update=\n",
    "        {\n",
    "            'messages': [ToolMessage(content=res['messages'][-1].content, tool_call_id=runtime.tool_call_id)]\n",
    "        }\n",
    "    )\n",
    "@tool\n",
    "def create_research(runtime: ToolRuntime[None | RLAgentState]) -> Command:\n",
    "    \"\"\"\n",
    "    This tool calls another agent who creates a research based on all the gathered information from tools\n",
    "    :return: Command\n",
    "    \"\"\"\n",
    "    messages = runtime.state['messages']\n",
    "\n",
    "    system_message = SystemMessage(content='You are an agent that conducts research based on the provided details and responds in a structured way')\n",
    "\n",
    "    res = model.with_structured_output(Research).invoke([system_message]+messages)\n",
    "    out_message = f\"\"\"\n",
    "    The Research conducted is as follows:\n",
    "    The Target Age group is {res.target_age_group},\n",
    "    The Target Gender is {res.target_gender},\n",
    "    The Target Demographic who is interested is {res.target_demographic},\n",
    "    \"\"\"\n",
    "\n",
    "    if runtime.state['first_run']:\n",
    "\n",
    "        return Command(update=\n",
    "            {\n",
    "                'messages' : [ToolMessage(content=out_message, tool_call_id=runtime.tool_call_id)],\n",
    "                'first_run': False,\n",
    "                'first_response': out_message,\n",
    "                'current_response': out_message,\n",
    "                'content': [res.target_age_group,res.target_gender,res.target_demographic]\n",
    "            }\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        return Command(update=\n",
    "            {\n",
    "                'messages' : [ToolMessage(content=out_message, tool_call_id=runtime.tool_call_id)],\n",
    "                'current_response': res,\n",
    "                'content': [res.target_age_group,res.target_gender,res.target_demographic]\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4568910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_to_google_messages(messages):\n",
    "#     new_messages = []\n",
    "#     for message in messages:\n",
    "#         if isinstance(message, SystemMessage):\n",
    "#             new_message = {\n",
    "#                 'role': 'system',\n",
    "#                 'content': message.content\n",
    "#             }\n",
    "#         elif isinstance(message, HumanMessage):\n",
    "#             new_message\n",
    "\n",
    "#         new_messages.append(new_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "465e7dee8b000b57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T11:18:48.894964Z",
     "start_time": "2025-11-07T11:18:48.836137Z"
    }
   },
   "outputs": [],
   "source": [
    "tool_agents = [search_browser, create_research]\n",
    "\n",
    "def planning_reasoning_step(state: RLAgentState):\n",
    "\n",
    "    if state['first_run']:\n",
    "\n",
    "        res = reasoning_chain.invoke(\n",
    "            {\n",
    "                'input' : state['user_input'],\n",
    "                'tools' : tools+tool_agents,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'messages' : AIMessage(content='The Plan is as follows : ' + res.steps + '\\n\\n' +\n",
    "                                           'The reasoning for them is as follows : ' + res.reasoning),\n",
    "            'reasoning' : res.reasoning,\n",
    "            'steps': res.steps,\n",
    "        }\n",
    "\n",
    "    else:\n",
    "\n",
    "        res = reasoning_with_insights_chain.invoke(\n",
    "            {\n",
    "                'input' : state['user_input'],\n",
    "                'insights': state['insights'],\n",
    "                'tools' : tools+tool_agents,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'messages' : AIMessage(),\n",
    "            'reasoning' : res.reasoning,\n",
    "            'steps' : res.steps,\n",
    "        }\n",
    "\n",
    "\n",
    "def router(state: RLAgentState):\n",
    "\n",
    "    messages = state['messages']\n",
    "    # parsed_messages = convert_to_google_messages(messages)\n",
    "\n",
    "    res = model.bind_tools(tool_agents).invoke(messages)\n",
    "\n",
    "    return {\n",
    "        'messages' : res\n",
    "    }\n",
    "\n",
    "def which_agent(state: RLAgentState)->Literal['search_agent','research_agent','Invalid',END]:\n",
    "\n",
    "    last_message = state['messages'][-1]\n",
    "    if len(last_message.tool_calls)>0:\n",
    "        tool = last_message.tool_calls[0]['name']\n",
    "        if tool == 'search_agent':\n",
    "            return 'search_agent'\n",
    "        elif tool == 'research_agent':\n",
    "            return 'research_agent'\n",
    "        else:\n",
    "            return 'Invalid'\n",
    "\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "def hitl(state: RLAgentState):\n",
    "\n",
    "    output = [state['reasoning'], state['current_response'], state['content']]\n",
    "    changes = interrupt(\n",
    "        output\n",
    "    )\n",
    "\n",
    "    if changes == 'Approved':\n",
    "        return {\n",
    "            'messages': AIMessage(content='No changes needed. Proceed to Finalise Research'),\n",
    "            'final_response': state['current_response'],\n",
    "            'jump_to': 'END'\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        return {\n",
    "            'messages': AIMessage(content='Changes added. Refer them to redo research'),\n",
    "            'changes': state['changes'].append(changes),\n",
    "            'jump_to': 'router'\n",
    "        }\n",
    "\n",
    "def is_approved(state: RLAgentState)->Literal[END,'router']:\n",
    "\n",
    "    if state['jump_to'] == 'END':\n",
    "        return END\n",
    "    else:\n",
    "        return 'router'\n",
    "\n",
    "# search_browser_node = ToolNode(name='search_agent', tools=[search_browser])\n",
    "# create_research_node = ToolNode(name='research_agent', tools=[create_research])\n",
    "tool_agents_node = ToolNode(name='tool_agents', tools=tool_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "64735d6fd5f9c0e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T11:08:55.802097Z",
     "start_time": "2025-11-07T11:08:55.794282Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpointer = InMemorySaver()\n",
    "config = {\n",
    "    'configurable' : {\n",
    "        'thread_id': '1'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d022fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_is_tool_call(state: RLAgentState)->Literal['tool_agents', END]:\n",
    "\n",
    "    last_message = state['messages'][-1]\n",
    "\n",
    "    if len(last_message.tool_calls)>0:\n",
    "        return 'tool_agents'\n",
    "    else:\n",
    "        return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ad74582e27f3fa81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T11:18:53.375430Z",
     "start_time": "2025-11-07T11:18:53.343837Z"
    }
   },
   "outputs": [],
   "source": [
    "graph = StateGraph(RLAgentState)\n",
    "\n",
    "graph.add_node('planning_reasoning', planning_reasoning_step)\n",
    "graph.add_node('router', router)\n",
    "graph.add_node('tool_agents', tool_agents_node)\n",
    "# graph.add_node('create_research', create_research)\n",
    "# graph.add_node('hitl', hitl)\n",
    "graph.add_edge(START, 'planning_reasoning')\n",
    "graph.add_edge('planning_reasoning', 'router')\n",
    "graph.add_conditional_edges('router', test_is_tool_call)\n",
    "# graph.add_conditional_edges('router', which_agent, {\n",
    "#     'search_agent': 'browser_search',\n",
    "#     'research_agent':'create_research',\n",
    "#     END : END\n",
    "# })\n",
    "graph.add_edge('tool_agents', 'router')\n",
    "# graph.add_edge('create_research', 'hitl')\n",
    "# graph.add_conditional_edges('hitl', is_approved, {\n",
    "#     END: END,\n",
    "#     'router': 'router'\n",
    "# })\n",
    "\n",
    "agent = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1c531c0b4cb614a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T11:18:57.607831Z",
     "start_time": "2025-11-07T11:18:56.247369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(agent.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7e3c7d80af339b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 'Search for Garnier Mens Shampoo and perform your reserach and give it to me'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "13d7ffd30453a0f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m res = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43muser_input\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minsights\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfirst_run\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcounter\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmax_loop\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3094\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3091\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3092\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3094\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3095\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3097\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3098\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3099\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3100\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3102\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3103\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3104\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3106\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3107\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3108\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3109\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2679\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2677\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2678\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2679\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2680\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2684\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2685\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2686\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2688\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2689\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:716\u001b[39m, in \u001b[36mToolNode._func\u001b[39m\u001b[34m(self, input, config, runtime)\u001b[39m\n\u001b[32m    714\u001b[39m input_types = [input_type] * \u001b[38;5;28mlen\u001b[39m(tool_calls)\n\u001b[32m    715\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m     outputs = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_one\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_calls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_runtimes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._combine_tool_outputs(outputs, input_type)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python\\Lib\\concurrent\\futures\\_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    621\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs.pop(), end_time - time.monotonic())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python\\Lib\\concurrent\\futures\\_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    319\u001b[39m         fut.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python\\Lib\\concurrent\\futures\\thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:546\u001b[39m, in \u001b[36mContextThreadPoolExecutor.map.<locals>._wrapped_fn\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapped_fn\u001b[39m(*args: Any) -> T:\n\u001b[32m--> \u001b[39m\u001b[32m546\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontexts\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:931\u001b[39m, in \u001b[36mToolNode._run_one\u001b[39m\u001b[34m(self, call, input_type, tool_runtime)\u001b[39m\n\u001b[32m    927\u001b[39m config = tool_runtime.config\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wrap_tool_call \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    930\u001b[39m     \u001b[38;5;66;03m# No wrapper - execute directly\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_tool_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[38;5;66;03m# Define execute callable that can be called multiple times\u001b[39;00m\n\u001b[32m    934\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(req: ToolCallRequest) -> ToolMessage | Command:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:880\u001b[39m, in \u001b[36mToolNode._execute_tool_sync\u001b[39m\u001b[34m(self, request, input_type, config)\u001b[39m\n\u001b[32m    877\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    879\u001b[39m     \u001b[38;5;66;03m# Error is handled - create error ToolMessage\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m880\u001b[39m     content = \u001b[43m_handle_tool_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_tool_errors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ToolMessage(\n\u001b[32m    882\u001b[39m         content=content,\n\u001b[32m    883\u001b[39m         name=call[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    884\u001b[39m         tool_call_id=call[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    885\u001b[39m         status=\u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    886\u001b[39m     )\n\u001b[32m    888\u001b[39m \u001b[38;5;66;03m# Process successful response\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:401\u001b[39m, in \u001b[36m_handle_tool_error\u001b[39m\u001b[34m(e, flag)\u001b[39m\n\u001b[32m    399\u001b[39m     content = flag\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(flag):\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     content = \u001b[43mflag\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore [assignment, call-arg]\u001b[39;00m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    403\u001b[39m     msg = (\n\u001b[32m    404\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGot unexpected type of `handle_tool_error`. Expected bool, str \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    405\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mor callable. Received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mflag\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    406\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:358\u001b[39m, in \u001b[36m_default_handle_tool_errors\u001b[39m\u001b[34m(e)\u001b[39m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ToolInvocationError):\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m e.message\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:833\u001b[39m, in \u001b[36mToolNode._execute_tool_sync\u001b[39m\u001b[34m(self, request, input_type, config)\u001b[39m\n\u001b[32m    831\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    832\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m         response = \u001b[43mtool\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    834\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    835\u001b[39m         \u001b[38;5;66;03m# Filter out errors for injected arguments\u001b[39;00m\n\u001b[32m    836\u001b[39m         filtered_errors = _filter_validation_errors(\n\u001b[32m    837\u001b[39m             exc,\n\u001b[32m    838\u001b[39m             \u001b[38;5;28mself\u001b[39m._tool_to_state_args.get(call[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m], {}),\n\u001b[32m    839\u001b[39m             \u001b[38;5;28mself\u001b[39m._tool_to_store_arg.get(call[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m]),\n\u001b[32m    840\u001b[39m             \u001b[38;5;28mself\u001b[39m._tool_to_runtime_arg.get(call[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m]),\n\u001b[32m    841\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:598\u001b[39m, in \u001b[36mBaseTool.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    590\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    592\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    595\u001b[39m     **kwargs: Any,\n\u001b[32m    596\u001b[39m ) -> Any:\n\u001b[32m    597\u001b[39m     tool_input, kwargs = _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:904\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    902\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    903\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    905\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    906\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:873\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m._run):\n\u001b[32m    872\u001b[39m         tool_kwargs |= {config_param: config}\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m     response = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.response_format == \u001b[33m\"\u001b[39m\u001b[33mcontent_and_artifact\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    875\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) != \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langchain_core\\tools\\structured.py:90\u001b[39m, in \u001b[36mStructuredTool._run\u001b[39m\u001b[34m(self, config, run_manager, *args, **kwargs)\u001b[39m\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m.func):\n\u001b[32m     89\u001b[39m         kwargs[config_param] = config\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mStructuredTool does not support sync invocation.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mcreate_research\u001b[39m\u001b[34m(runtime)\u001b[39m\n\u001b[32m     30\u001b[39m messages = runtime.state[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     32\u001b[39m system_message = SystemMessage(content=\u001b[33m'\u001b[39m\u001b[33mYou are an agent that conducts research based on the provided details and responds in a structured way\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m res = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_structured_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mResearch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43msystem_message\u001b[49m\u001b[43m]\u001b[49m\u001b[43m+\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m out_message = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[33mThe Research conducted is as follows:\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[33mThe Target Age group is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres.target_age_group\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[33mThe Target Gender is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres.target_gender\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[33mThe Target Demographic who is interested is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres.target_demographic\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m runtime.state[\u001b[33m'\u001b[39m\u001b[33mfirst_run\u001b[39m\u001b[33m'\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3088\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3086\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3087\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3088\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3089\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3090\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5489\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5482\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5483\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5484\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5487\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5488\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5490\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5491\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5492\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5493\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:2012\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   2009\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2010\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m2012\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:383\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    368\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    370\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    375\u001b[39m     **kwargs: Any,\n\u001b[32m    376\u001b[39m ) -> AIMessage:\n\u001b[32m    377\u001b[39m     config = ensure_config(config)\n\u001b[32m    378\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    379\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    380\u001b[39m         cast(\n\u001b[32m    381\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    382\u001b[39m             \u001b[38;5;28mself\u001b[39m.generate_prompt(\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m                 [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m],\n\u001b[32m    384\u001b[39m                 stop=stop,\n\u001b[32m    385\u001b[39m                 callbacks=config.get(\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    386\u001b[39m                 tags=config.get(\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    387\u001b[39m                 metadata=config.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    388\u001b[39m                 run_name=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    389\u001b[39m                 run_id=config.pop(\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    390\u001b[39m                 **kwargs,\n\u001b[32m    391\u001b[39m             ).generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    392\u001b[39m         ).message,\n\u001b[32m    393\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\coding stuff\\Personal Projects\\Agentic-AI-Playground\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:366\u001b[39m, in \u001b[36mBaseChatModel._convert_input\u001b[39m\u001b[34m(self, model_input)\u001b[39m\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages=convert_to_messages(model_input))\n\u001b[32m    362\u001b[39m msg = (\n\u001b[32m    363\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid input type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model_input)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    364\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mMust be a PromptValue, str, or list of BaseMessages.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    365\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[31mValueError\u001b[39m: Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages.",
      "During task with name 'tool_agents' and id '49e9d852-c696-ae7a-e8a3-f01c90653041'"
     ]
    }
   ],
   "source": [
    "res = agent.invoke(\n",
    "    {\n",
    "        'messages': HumanMessage(content=input),\n",
    "        'user_input': input,\n",
    "        'insights': '',\n",
    "        'first_run': True,\n",
    "        'counter': 0,\n",
    "        'max_loop': 2,\n",
    "    },\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d5fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in res['messages']:\n",
    "    msg.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
